from typing import Dict, List, Union, AsyncIterable, Optional, Any
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from multi_agent_orchestrator.types import ConversationMessage
from multi_agent_orchestrator.utils import Logger

@dataclass
class AgentProcessingResult:
    user_input: str
    agent_id: str
    agent_name: str
    user_id: str
    session_id: str
    additional_params: Dict[str, any] = field(default_factory=dict)

@dataclass
class AgentResponse:
    metadata: AgentProcessingResult
    output: Union[Any, str]
    streaming: bool


class AgentCallbacks:
    def on_llm_new_token(self, token: str) -> None:
        """
        Callback triggered when a new token is generated by the LLM.

        Args:
            token (str): The newly generated token from the language model
        """
        pass

    def on_llm_start(self, **kwargs) -> None:
        """
        Callback invoked when the LLM starts processing.
        Useful for initialization or setup before LLM execution.

        Args:
            **kwargs: Additional arguments passed during LLM initialization
        """
        pass

    def on_llm_end(self, **kwargs) -> None:
        """
        Callback triggered when the LLM completes its execution.
        Handle cleanup or final processing steps here.

        Args:
            **kwargs: Arguments containing LLM completion details
        """
        pass

    def on_llm_error(self, **kwargs) -> None:
        """
        Handles errors that occur during LLM execution.

        Args:
            **kwargs: Arguments containing LLM error details
        """
        pass

    def on_llm_trace(self, **kwargs) -> None:
        """
        Callback for tracing/logging LLM operations.
        Useful for debugging and monitoring LLM behavior.

        Args:
            **kwargs: Trace-related information and metadata
        """
        pass

    def on_tool_start(self, **kwargs) -> None:
        """
        Triggered when a tool begins execution.
        Use this for tool-specific initialization or logging.

        Args:
            **kwargs: Tool configuration and initialization parameters
        """
        pass

    def on_tool_end(self, **kwargs) -> None:
        """
        Called when a tool completes its execution.
        Handle tool cleanup and result processing here.

        Args:
            **kwargs: Tool execution results and metadata
        """
        pass

    def on_tool_error(self, **kwargs) -> None:
        """
        Handles errors that occur during tool execution.

        Args:
            **kwargs: Error details and context
        """
        pass

    def on_retriever_start(self, **kwargs) -> None:
        """
        Triggered when a retriever begins execution.
        Useful for initialization or setup before retriever execution.

        Args:
            **kwargs: Retriever configuration and initialization parameters
        """
        pass

    def on_retriever_end(self, **kwargs) -> None:
        """
        Called when a retriever completes its execution.
        Handle retriever cleanup and result processing here.

        Args:
            **kwargs: Retriever execution results and metadata
        """
        pass

    def on_retriever_error(self, **kwargs) -> None:
        """
        Handles errors that occur during retriever execution.

        Args:
            **kwargs: Error details and context
        """
        pass




@dataclass
class AgentOptions:
    name: str
    description: str
    model_id: Optional[str] = None
    region: Optional[str] = None
    save_chat: bool = True
    callbacks: Optional[AgentCallbacks] = None
    # Optional: Flag to enable/disable agent debug trace logging
    # If true, the agent will log additional debug information
    LOG_AGENT_DEBUG_TRACE: Optional[bool] = False


class Agent(ABC):
    def __init__(self, options: AgentOptions):
        self.name = options.name
        self.id = self.generate_key_from_name(options.name)
        self.description = options.description
        self.save_chat = options.save_chat
        self.callbacks = options.callbacks if options.callbacks is not None else AgentCallbacks()
        self.LOG_AGENT_DEBUG_TRACE = options.LOG_AGENT_DEBUG_TRACE if options.LOG_AGENT_DEBUG_TRACE is not None else False

    def is_streaming_enabled(self) -> bool:
        return False

    @staticmethod
    def generate_key_from_name(name: str) -> str:
        import re
        # Remove special characters and replace spaces with hyphens
        key = re.sub(r'[^a-zA-Z\s-]', '', name)
        key = re.sub(r'\s+', '-', key)
        return key.lower()

    @abstractmethod
    async def process_request(
        self,
        input_text: str,
        user_id: str,
        session_id: str,
        chat_history: List[ConversationMessage],
        additional_params: Optional[Dict[str, str]] = None
    ) -> Union[ConversationMessage, AsyncIterable[any]]:
        pass

    def log_debug(self, class_name, message, data=None):
        if self.LOG_AGENT_DEBUG_TRACE:
            prefix = f"> {class_name} \n> {self.name} \n>"
            if data:
                Logger.info(f"{prefix} {message} \n> {data}")
            else:
                Logger.info(f"{prefix} {message} \n>")
